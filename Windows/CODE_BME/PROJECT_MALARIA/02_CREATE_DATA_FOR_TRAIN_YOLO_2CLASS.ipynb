{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7a86f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# üìÇ INPUT PATH (‡πÉ‡∏ä‡πâ DATA_SET_2CLASS)\n",
    "base_dir = r\"C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\"\n",
    "input_dir = os.path.join(base_dir, \"DATA_SET_2CLASS\")\n",
    "train_img_dir = os.path.join(input_dir, \"train_images\")\n",
    "test_img_dir = os.path.join(input_dir, \"test_images\")\n",
    "train_csv = os.path.join(input_dir, \"train.csv\")\n",
    "test_csv = os.path.join(input_dir, \"test.csv\")\n",
    "\n",
    "# üìÇ OUTPUT PATH ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö YOLOv8 (2-CLASS)\n",
    "output_dir = os.path.join(input_dir, \"YOLOV8\")\n",
    "\n",
    "# üìã ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "train_image = os.listdir(train_img_dir)\n",
    "train_label = pd.read_csv(train_csv)\n",
    "test_image = os.listdir(test_img_dir)\n",
    "test_label = pd.read_csv(test_csv)\n",
    "\n",
    "# üîÄ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ K-Fold Cross Validation\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "train_image_df = pd.DataFrame({\"filename\": train_image})\n",
    "\n",
    "# üéØ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏õ‡∏•‡∏á label ‡πÄ‡∏õ‡πá‡∏ô binary\n",
    "def label_to_binary(label: str) -> int:\n",
    "    return 0 if label == \"normal\" else 1\n",
    "\n",
    "# üì¶ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏õ‡∏•‡∏á bbox ‡πÄ‡∏õ‡πá‡∏ô YOLO format\n",
    "def convert_bbox(xmin, ymin, xmax, ymax, img_width, img_height):\n",
    "    center_x = (xmin + xmax) / (2 * img_width)\n",
    "    center_y = (ymin + ymax) / (2 * img_height)\n",
    "    width = (xmax - xmin) / img_width\n",
    "    height = (ymax - ymin) / img_height\n",
    "    return center_x, center_y, width, height\n",
    "\n",
    "# üîÅ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ fold\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_image_df)):\n",
    "    fold_dir = os.path.join(output_dir, f\"fold_{fold+1}\")\n",
    "\n",
    "    image_train_dir = os.path.join(fold_dir, \"train\", \"images\")\n",
    "    label_train_dir = os.path.join(fold_dir, \"train\", \"labels\")\n",
    "    image_val_dir = os.path.join(fold_dir, \"validation\", \"images\")\n",
    "    label_val_dir = os.path.join(fold_dir, \"validation\", \"labels\")\n",
    "    image_test_dir = os.path.join(fold_dir, \"test\", \"images\")\n",
    "    label_test_dir = os.path.join(fold_dir, \"test\", \"labels\")\n",
    "\n",
    "    for d in [image_train_dir, label_train_dir, image_val_dir, label_val_dir, image_test_dir, label_test_dir]:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    train_fold_df = train_image_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_image_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    def save_images_and_labels(image_list, label_df, image_src_dir, image_dst_dir, label_dst_dir):\n",
    "        for image_name in image_list:\n",
    "            src_path = os.path.join(image_src_dir, image_name)\n",
    "            dst_path = os.path.join(image_dst_dir, image_name)\n",
    "            if os.path.exists(src_path):\n",
    "                Image.open(src_path).save(dst_path)\n",
    "\n",
    "                label_data = label_df[label_df['image_name'] == image_name]\n",
    "                if not label_data.empty:\n",
    "                    img = Image.open(src_path)\n",
    "                    img_width, img_height = img.size\n",
    "                    label_file_path = os.path.join(label_dst_dir, os.path.splitext(image_name)[0] + \".txt\")\n",
    "                    with open(label_file_path, 'w') as f:\n",
    "                        for _, row in label_data.iterrows():\n",
    "                            class_id = label_to_binary(row['label'])\n",
    "                            cx, cy, w, h = convert_bbox(row['xmin'], row['ymin'], row['xmax'], row['ymax'], img_width, img_height)\n",
    "                            f.write(f\"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "    # ‚úèÔ∏è Train / Val / Test\n",
    "    save_images_and_labels(train_fold_df[\"filename\"], train_label, train_img_dir, image_train_dir, label_train_dir)\n",
    "    save_images_and_labels(val_fold_df[\"filename\"], train_label, train_img_dir, image_val_dir, label_val_dir)\n",
    "    save_images_and_labels(test_image, test_label, test_img_dir, image_test_dir, label_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af67b203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå YAML ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fold 1: C:/Users/BMEi/Documents/GitHub/WORK/Windows/CODE_BME/PROJECT_MALARIA/DATA_SET_2CLASS/YOLOV8/fold_1/fold_1.yaml\n",
      "‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå YAML ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fold 2: C:/Users/BMEi/Documents/GitHub/WORK/Windows/CODE_BME/PROJECT_MALARIA/DATA_SET_2CLASS/YOLOV8/fold_2/fold_2.yaml\n",
      "‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå YAML ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fold 3: C:/Users/BMEi/Documents/GitHub/WORK/Windows/CODE_BME/PROJECT_MALARIA/DATA_SET_2CLASS/YOLOV8/fold_3/fold_3.yaml\n",
      "‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå YAML ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fold 4: C:/Users/BMEi/Documents/GitHub/WORK/Windows/CODE_BME/PROJECT_MALARIA/DATA_SET_2CLASS/YOLOV8/fold_4/fold_4.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_yaml_files(dataset_path, num_folds, class_names):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå .yaml ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ fold ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏£‡∏ô YOLO\n",
    "\n",
    "    Parameters:\n",
    "        dataset_path (str): ‡∏û‡∏≤‡∏ò‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á dataset\n",
    "        num_folds (int): ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô folds ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á\n",
    "        class_names (dict): dictionary ‡∏Ç‡∏≠‡∏á class names ‡πÄ‡∏ä‡πà‡∏ô {0: 'normal', 1: 'abnormal'}\n",
    "    \"\"\"\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        fold_dir = os.path.join(dataset_path, f\"fold_{fold}\").replace('\\\\', '/')\n",
    "        yaml_path = os.path.join(fold_dir, f\"fold_{fold}.yaml\").replace('\\\\', '/')\n",
    "\n",
    "        yaml_content = f\"\"\"# YOLO dataset config file for Fold {fold}\n",
    "train: {fold_dir}/train/images\n",
    "val: {fold_dir}/validation/images\n",
    "test: {fold_dir}/test/images\n",
    "\n",
    "nc: {len(class_names)}\n",
    "names: [{', '.join(f'\"{name}\"' for name in class_names.values())}]\n",
    "\"\"\"\n",
    "\n",
    "        with open(yaml_path, \"w\", encoding=\"utf-8\") as yaml_file:\n",
    "            yaml_file.write(yaml_content)\n",
    "\n",
    "        print(f\"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå YAML ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fold {fold}: {yaml_path}\")\n",
    "\n",
    "# üîß ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:\n",
    "dataset_path = r\"C:/Users/BMEi/Documents/GitHub/WORK/Windows/CODE_BME/PROJECT_MALARIA/DATA_SET_2CLASS/YOLOV8\"\n",
    "num_folds = 4\n",
    "class_names = {\n",
    "    0: \"normal\",\n",
    "    1: \"abnormal\"\n",
    "}\n",
    "\n",
    "create_yaml_files(dataset_path, num_folds, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d891ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 1 =====\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_1\\fold_1.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=runs_fold_2class, name=fold_1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs_fold_2class\\fold_1\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_1\\train\\labels... 905 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 905/905 [00:01<00:00, 744.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_1\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_1\\validation\\labels... 302 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 302/302 [00:00<00:00, 429.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_1\\validation\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs_fold_2class\\fold_1\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns_fold_2class\\fold_1\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      4.25G     0.9853      1.852     0.9887        494        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:10<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978      0.854      0.499      0.601      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      5.69G     0.8651     0.7125     0.9182        518        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978      0.921       0.89      0.938      0.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10       5.7G     0.8196     0.5933     0.9114        566        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978      0.883      0.899      0.941      0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      5.72G     0.8107     0.5505     0.9057        452        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978      0.917      0.928      0.967      0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      5.74G     0.7937     0.5158     0.9048        476        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978      0.926      0.948      0.977      0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      5.76G     0.7653     0.4866     0.8976        811        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:08<00:00,  7.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978      0.938      0.937      0.973      0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      5.76G     0.7636     0.4726     0.8893        577        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978       0.95      0.949      0.978      0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      5.79G     0.7514     0.4583     0.8918        717        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978      0.928      0.935      0.974      0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      5.81G     0.7429     0.4424     0.8883        528        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978      0.958      0.957      0.982      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      5.83G     0.7337     0.4295     0.8841        739        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:08<00:00,  6.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978      0.962      0.952      0.982       0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.034 hours.\n",
      "Optimizer stripped from runs_fold_2class\\fold_1\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs_fold_2class\\fold_1\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs_fold_2class\\fold_1\\weights\\best.pt...\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:08<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978      0.962      0.952      0.982       0.81\n",
      "                normal        302      19339      0.983      0.979      0.993      0.822\n",
      "              abnormal        260        639       0.94      0.925      0.972      0.797\n",
      "Speed: 0.4ms preprocess, 2.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns_fold_2class\\fold_1\u001b[0m\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_1\\validation\\labels.cache... 302 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 302/302 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:06<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19978      0.962      0.952      0.982      0.811\n",
      "                normal        302      19339      0.983      0.979      0.993      0.823\n",
      "              abnormal        260        639      0.941      0.925      0.972      0.799\n",
      "Speed: 0.5ms preprocess, 3.4ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns_fold_2class\\fold_12\u001b[0m\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CPU (Intel Core(TM) i7-14700F)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs_fold_2class\\fold_1\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.49...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.7s, saved as 'runs_fold_2class\\fold_1\\weights\\best.onnx' (11.7 MB)\n",
      "\n",
      "Export complete (0.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\runs_fold_2class\\fold_1\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs_fold_2class\\fold_1\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs_fold_2class\\fold_1\\weights\\best.onnx imgsz=640 data=C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_1\\fold_1.yaml  \n",
      "Visualize:       https://netron.app\n",
      "‚úÖ Exported and saved to yolov8n_fold_1_2class.onnx\n",
      "===== Fold 2 =====\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_2\\fold_2.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=runs_fold_2class, name=fold_2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs_fold_2class\\fold_2\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_2\\train\\labels... 905 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 905/905 [00:00<00:00, 945.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_2\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_2\\validation\\labels... 302 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 302/302 [00:00<00:00, 645.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_2\\validation\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs_fold_2class\\fold_2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns_fold_2class\\fold_2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      4.26G     0.9909      1.862     0.9912        460        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839      0.692      0.492      0.541      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      4.94G     0.8605     0.7186     0.9176        722        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  8.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839      0.836       0.88      0.922      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      4.94G     0.8146     0.5936     0.9092        517        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839      0.825      0.887      0.894       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      4.94G     0.8074     0.5499     0.9021        783        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839      0.903      0.917      0.964      0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      4.95G     0.7893     0.5091     0.9016        597        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839      0.933      0.935      0.967      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      4.96G     0.7608     0.4758     0.8931        783        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839      0.946       0.94      0.972       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      4.97G     0.7625     0.4679     0.8904        479        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839      0.926      0.939       0.97      0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         5G     0.7629     0.4622     0.8933        469        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839      0.946      0.936      0.972      0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      5.02G     0.7383     0.4399     0.8854        513        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839       0.91      0.958      0.968      0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      5.03G     0.7302     0.4334     0.8834        519        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839      0.947      0.943      0.975      0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.029 hours.\n",
      "Optimizer stripped from runs_fold_2class\\fold_2\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs_fold_2class\\fold_2\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs_fold_2class\\fold_2\\weights\\best.pt...\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:05<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839      0.947      0.943      0.975      0.794\n",
      "                normal        302      19180      0.969      0.987      0.992      0.816\n",
      "              abnormal        248        659      0.925      0.898      0.957      0.771\n",
      "Speed: 0.2ms preprocess, 1.5ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns_fold_2class\\fold_2\u001b[0m\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_2\\validation\\labels.cache... 302 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 302/302 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:06<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19839      0.947      0.943      0.975      0.793\n",
      "                normal        302      19180      0.969      0.987      0.992      0.816\n",
      "              abnormal        248        659      0.925      0.899      0.957       0.77\n",
      "Speed: 0.4ms preprocess, 3.3ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns_fold_2class\\fold_22\u001b[0m\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CPU (Intel Core(TM) i7-14700F)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs_fold_2class\\fold_2\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.49...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.4s, saved as 'runs_fold_2class\\fold_2\\weights\\best.onnx' (11.7 MB)\n",
      "\n",
      "Export complete (0.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\runs_fold_2class\\fold_2\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs_fold_2class\\fold_2\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs_fold_2class\\fold_2\\weights\\best.onnx imgsz=640 data=C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_2\\fold_2.yaml  \n",
      "Visualize:       https://netron.app\n",
      "‚úÖ Exported and saved to yolov8n_fold_2_2class.onnx\n",
      "===== Fold 3 =====\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_3\\fold_3.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=runs_fold_2class, name=fold_3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs_fold_2class\\fold_3\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_3\\train\\labels... 905 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 905/905 [00:00<00:00, 961.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_3\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_3\\validation\\labels... 302 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 302/302 [00:00<00:00, 642.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_3\\validation\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs_fold_2class\\fold_3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns_fold_2class\\fold_3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      4.39G     0.9756       1.86     0.9845        691        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.784      0.558      0.644      0.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      5.12G     0.8563     0.7117     0.9127        502        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  8.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.837      0.869      0.923       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      5.12G     0.8241     0.5996     0.9106        624        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.879      0.885      0.957      0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      5.12G     0.8061     0.5465     0.9038        508        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.754      0.891      0.943       0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      5.12G     0.7905     0.5109     0.8973        529        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.912      0.936      0.973      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      5.12G       0.77     0.4836      0.895        531        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.942      0.945      0.969      0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      5.12G     0.7597     0.4699     0.8898        483        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.895      0.913      0.956      0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      5.14G     0.7477     0.4558     0.8865        646        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.949      0.948       0.98      0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      5.16G     0.7367     0.4391     0.8868        473        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.954       0.95      0.978      0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      5.17G     0.7329      0.433     0.8814        927        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.959      0.947       0.98        0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.029 hours.\n",
      "Optimizer stripped from runs_fold_2class\\fold_3\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs_fold_2class\\fold_3\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs_fold_2class\\fold_3\\weights\\best.pt...\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.959      0.947       0.98      0.799\n",
      "                normal        302      19267      0.973      0.983      0.993       0.81\n",
      "              abnormal        261        703      0.944      0.911      0.968      0.789\n",
      "Speed: 0.2ms preprocess, 1.6ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns_fold_2class\\fold_3\u001b[0m\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_3\\validation\\labels.cache... 302 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 302/302 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:06<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        302      19970      0.959      0.947      0.982      0.801\n",
      "                normal        302      19267      0.973      0.983      0.993      0.811\n",
      "              abnormal        261        703      0.944      0.912      0.971      0.791\n",
      "Speed: 0.4ms preprocess, 3.6ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns_fold_2class\\fold_32\u001b[0m\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CPU (Intel Core(TM) i7-14700F)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs_fold_2class\\fold_3\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.49...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as 'runs_fold_2class\\fold_3\\weights\\best.onnx' (11.7 MB)\n",
      "\n",
      "Export complete (0.6s)\n",
      "Results saved to \u001b[1mC:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\runs_fold_2class\\fold_3\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs_fold_2class\\fold_3\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs_fold_2class\\fold_3\\weights\\best.onnx imgsz=640 data=C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_3\\fold_3.yaml  \n",
      "Visualize:       https://netron.app\n",
      "‚úÖ Exported and saved to yolov8n_fold_3_2class.onnx\n",
      "===== Fold 4 =====\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_4\\fold_4.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=runs_fold_2class, name=fold_4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs_fold_2class\\fold_4\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_4\\train\\labels... 906 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 906/906 [00:01<00:00, 828.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_4\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_4\\validation\\labels... 301 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 301/301 [00:00<00:00, 539.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_4\\validation\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs_fold_2class\\fold_4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns_fold_2class\\fold_4\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      4.01G     0.9709      1.827     0.9778        585        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252      0.768      0.515      0.568      0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      5.35G     0.8575     0.7142     0.9179        586        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252      0.809      0.796      0.893      0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      5.35G       0.82     0.5996     0.9057        528        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252      0.857      0.899      0.932      0.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      5.35G     0.8173     0.5454      0.906        641        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252      0.877      0.921      0.964      0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      5.35G     0.7835     0.5075     0.9018        583        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252      0.942      0.928      0.968      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      5.35G     0.7649     0.4854       0.89        851        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252      0.865      0.916      0.962      0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      5.35G     0.7484     0.4715     0.8869        464        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252       0.92      0.932      0.969      0.787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      5.35G     0.7426     0.4536     0.8902        555        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252      0.952      0.936      0.978      0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      5.36G      0.738     0.4412     0.8835        588        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252      0.938      0.956      0.978      0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      5.38G     0.7286     0.4267     0.8825        680        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:06<00:00,  8.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252      0.948      0.948      0.979      0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.029 hours.\n",
      "Optimizer stripped from runs_fold_2class\\fold_4\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs_fold_2class\\fold_4\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs_fold_2class\\fold_4\\weights\\best.pt...\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:05<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252      0.948      0.949      0.979      0.805\n",
      "                normal        301      19563      0.964      0.985      0.992      0.817\n",
      "              abnormal        261        689      0.933      0.913      0.966      0.794\n",
      "Speed: 0.2ms preprocess, 1.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns_fold_2class\\fold_4\u001b[0m\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_4\\validation\\labels.cache... 301 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 301/301 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        301      20252      0.949      0.948      0.979      0.805\n",
      "                normal        301      19563      0.964      0.985      0.992      0.817\n",
      "              abnormal        261        689      0.933      0.912      0.966      0.794\n",
      "Speed: 0.4ms preprocess, 3.0ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns_fold_2class\\fold_42\u001b[0m\n",
      "Ultralytics 8.3.99  Python-3.9.13 torch-2.6.0+cu126 CPU (Intel Core(TM) i7-14700F)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs_fold_2class\\fold_4\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.49...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.4s, saved as 'runs_fold_2class\\fold_4\\weights\\best.onnx' (11.7 MB)\n",
      "\n",
      "Export complete (0.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\runs_fold_2class\\fold_4\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs_fold_2class\\fold_4\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs_fold_2class\\fold_4\\weights\\best.onnx imgsz=640 data=C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_4\\fold_4.yaml  \n",
      "Visualize:       https://netron.app\n",
      "‚úÖ Exported and saved to yolov8n_fold_4_2class.onnx\n",
      "‚úÖ All folds completed.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# üîÅ ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå YAML ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 2 ‡∏Ñ‡∏•‡∏≤‡∏™\n",
    "fold_paths = [\n",
    "    r'C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_1\\fold_1.yaml',\n",
    "    r'C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_2\\fold_2.yaml',\n",
    "    r'C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_3\\fold_3.yaml',\n",
    "    r'C:\\Users\\BMEi\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_MALARIA\\DATA_SET_2CLASS\\YOLOV8\\fold_4\\fold_4.yaml',\n",
    "]\n",
    "\n",
    "# üöÄ ‡πÄ‡∏ó‡∏£‡∏ô + ‡∏ß‡∏≤‡∏•‡∏¥‡πÄ‡∏î‡∏ï + Export ONNX\n",
    "for i, path in enumerate(fold_paths, start=1):\n",
    "    print(f\"===== Fold {i} =====\")\n",
    "    model = YOLO('yolov8n.pt')\n",
    "\n",
    "    model.train(data=path, epochs=10, device='0', project='runs_fold_2class', name=f'fold_{i}')\n",
    "    model.val(device='0')\n",
    "\n",
    "    # Export ONNX\n",
    "    export_result = model.export(format='onnx')\n",
    "    \n",
    "    # Move exported ONNX model to custom filename\n",
    "    exported_path = export_result[0] if isinstance(export_result, (list, tuple)) else export_result\n",
    "    target_path = f'yolov8n_fold_{i}_2class.onnx'\n",
    "    if os.path.exists(exported_path):\n",
    "        shutil.move(exported_path, target_path)\n",
    "        print(f\"‚úÖ Exported and saved to {target_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Export failed for fold {i}\")\n",
    "\n",
    "print(\"‚úÖ All folds completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44630772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Detection Summary:\n",
      "+--------+------------+--------------------+----------------------+---------------------------+\n",
      "| Fold   |   Total GT |   Total Prediction | Detection Accuracy   | Classification Accuracy   |\n",
      "+========+============+====================+======================+===========================+\n",
      "| Fold 1 |       5922 |               6673 | 98.51%               | 95.31%                    |\n",
      "+--------+------------+--------------------+----------------------+---------------------------+\n",
      "| Fold 2 |       5922 |               6593 | 97.99%               | 94.19%                    |\n",
      "+--------+------------+--------------------+----------------------+---------------------------+\n",
      "| Fold 3 |       5922 |               6615 | 98.21%               | 94.63%                    |\n",
      "+--------+------------+--------------------+----------------------+---------------------------+\n",
      "| Fold 4 |       5922 |               6474 | 96.99%               | 93.28%                    |\n",
      "+--------+------------+--------------------+----------------------+---------------------------+\n",
      "\n",
      "üñºÔ∏è Drawing results (only class 1)...\n",
      "\n",
      "üìÑ Exported per-fold summary to 'summary_per_fold.csv'\n"
     ]
    }
   ],
   "source": [
    "# üîß ‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° (import ‡πÅ‡∏•‡∏∞‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô IOU)\n",
    "import os\n",
    "import cv2\n",
    "import logging\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from tabulate import tabulate\n",
    "\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.ERROR)\n",
    "\n",
    "def calculate_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n",
    "    return iou\n",
    "\n",
    "# üìÅ ‡∏û‡∏≤‡∏ò\n",
    "base_path = r\"C:/Users/BMEi/Documents/GitHub/WORK/Windows/CODE_BME/PROJECT_MALARIA/DATA_SET_2CLASS/YOLOV8\"\n",
    "model_base_path = r\"C:/Users/BMEi/Documents/GitHub/WORK/Windows/CODE_BME/PROJECT_MALARIA\"\n",
    "save_image_folder = \"results_images_2class_abnormal_only\"\n",
    "iou_threshold = 0.5\n",
    "\n",
    "os.makedirs(save_image_folder, exist_ok=True)\n",
    "\n",
    "results_table = []\n",
    "detailed_results = []\n",
    "false_positive_images = []\n",
    "fold_stats = {}\n",
    "\n",
    "# üîÅ ‡∏ß‡∏ô 4 folds\n",
    "for i in range(1, 5):\n",
    "    model_path = os.path.join(model_base_path, f\"yolov8n_fold_{i}_2class.onnx\")\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    images_folder = os.path.join(base_path, f\"fold_{i}\", \"test\", \"images\")\n",
    "    labels_folder = os.path.join(base_path, f\"fold_{i}\", \"test\", \"labels\")\n",
    "\n",
    "    total_gt = 0\n",
    "    total_pred = 0\n",
    "    correct_detect = 0\n",
    "    correct_class = 0\n",
    "\n",
    "    if i not in fold_stats:\n",
    "        fold_stats[i] = {\"TP\": 0, \"FP\": 0, \"FN\": 0, \"Images\": 0}\n",
    "\n",
    "    for filename in os.listdir(images_folder):\n",
    "        if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(images_folder, filename)\n",
    "        label_path = os.path.join(labels_folder, filename.rsplit(\".\", 1)[0] + \".txt\")\n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        height, width = image.shape[:2]\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # ‚úÖ Load GT\n",
    "        gt_boxes = []\n",
    "        with open(label_path, \"r\") as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                class_id, x, y, w, h = map(float, parts)\n",
    "                x *= width\n",
    "                y *= height\n",
    "                w *= width\n",
    "                h *= height\n",
    "                gt_boxes.append([int(class_id), x - w/2, y - h/2, x + w/2, y + h/2])\n",
    "\n",
    "        results = model(image_path)\n",
    "        pred_boxes = [\n",
    "            [int(box.cls[0].item()), *box.xyxy[0].cpu().numpy().tolist()]\n",
    "            for box in results[0].boxes\n",
    "        ]\n",
    "        total_pred += len(pred_boxes)\n",
    "\n",
    "        matched = set()\n",
    "        pred_matched_flags = [False] * len(pred_boxes)\n",
    "\n",
    "        for gt_class, gt_x1, gt_y1, gt_x2, gt_y2 in gt_boxes:\n",
    "            total_gt += 1\n",
    "            matched_pred = None\n",
    "            best_iou = 0\n",
    "            matched_pred_class = None\n",
    "\n",
    "            for j, (pred_class, pred_x1, pred_y1, pred_x2, pred_y2) in enumerate(pred_boxes):\n",
    "                if pred_matched_flags[j]:\n",
    "                    continue\n",
    "                iou = calculate_iou([gt_x1, gt_y1, gt_x2, gt_y2], [pred_x1, pred_y1, pred_x2, pred_y2])\n",
    "                if iou >= iou_threshold and iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    matched_pred = j\n",
    "                    matched_pred_class = pred_class\n",
    "\n",
    "            if matched_pred is not None:\n",
    "                correct_detect += 1\n",
    "                if matched_pred_class == gt_class:\n",
    "                    correct_class += 1\n",
    "                pred_matched_flags[matched_pred] = True\n",
    "                matched.add(matched_pred)\n",
    "\n",
    "                pred_x1, pred_y1, pred_x2, pred_y2 = pred_boxes[matched_pred][1:]\n",
    "                detailed_results.append({\n",
    "                    \"Fold\": i, \"Image\": filename,\n",
    "                    \"GT_Class\": gt_class,\n",
    "                    \"GT_Box\": f\"{gt_x1:.1f},{gt_y1:.1f},{gt_x2:.1f},{gt_y2:.1f}\",\n",
    "                    \"Pred_Class\": matched_pred_class,\n",
    "                    \"Pred_Box\": f\"{pred_x1:.1f},{pred_y1:.1f},{pred_x2:.1f},{pred_y2:.1f}\",\n",
    "                    \"IOU\": f\"{best_iou:.3f}\",\n",
    "                    \"Match\": \"Yes\",\n",
    "                    \"Class_Correct\": \"Yes\" if matched_pred_class == gt_class else \"No\"\n",
    "                })\n",
    "            else:\n",
    "                detailed_results.append({\n",
    "                    \"Fold\": i, \"Image\": filename,\n",
    "                    \"GT_Class\": gt_class,\n",
    "                    \"GT_Box\": f\"{gt_x1:.1f},{gt_y1:.1f},{gt_x2:.1f},{gt_y2:.1f}\",\n",
    "                    \"Pred_Class\": None,\n",
    "                    \"Pred_Box\": None,\n",
    "                    \"IOU\": None,\n",
    "                    \"Match\": \"No\",\n",
    "                    \"Class_Correct\": \"No\"\n",
    "                })\n",
    "\n",
    "        false_positive_images.append((i, filename, image_rgb.copy(), gt_boxes, pred_boxes, matched, pred_matched_flags))\n",
    "\n",
    "    detect_acc = correct_detect / total_gt * 100 if total_gt > 0 else 0\n",
    "    class_acc = correct_class / total_gt * 100 if total_gt > 0 else 0\n",
    "    results_table.append([\n",
    "        f\"Fold {i}\",\n",
    "        total_gt,\n",
    "        total_pred,\n",
    "        f\"{detect_acc:.2f}%\",\n",
    "        f\"{class_acc:.2f}%\"\n",
    "    ])\n",
    "\n",
    "# ‚úÖ Summary table\n",
    "print(\"\\nüìä Detection Summary:\")\n",
    "print(tabulate(results_table, headers=[\"Fold\", \"Total GT\", \"Total Prediction\", \"Detection Accuracy\", \"Classification Accuracy\"], tablefmt=\"grid\"))\n",
    "pd.DataFrame(results_table, columns=[\"Fold\", \"Total GT\", \"Total Prediction\", \"Detection Accuracy\", \"Classification Accuracy\"]).to_csv(\"summary_table.csv\", index=False)\n",
    "\n",
    "# ‚úÖ Export detailed results\n",
    "pd.DataFrame(detailed_results).to_csv(\"detection_detailed_results.csv\", index=False)\n",
    "\n",
    "# ‚úÖ Draw only class 1\n",
    "print(\"\\nüñºÔ∏è Drawing results (only class 1)...\\n\")\n",
    "for fold, filename, image_rgb, gt_boxes, pred_boxes, matched, pred_matched_flags in false_positive_images:\n",
    "    fold_dir = os.path.join(save_image_folder, f\"fold{fold}\")\n",
    "    os.makedirs(fold_dir, exist_ok=True)\n",
    "\n",
    "    gt_img = image_rgb.copy()\n",
    "    fn_count = 0\n",
    "    for gt_class, x1, y1, x2, y2 in gt_boxes:\n",
    "        if gt_class != 1: continue  # üí• show GT only for class 1\n",
    "\n",
    "        is_fn = True\n",
    "        for j, (pred_class, px1, py1, px2, py2) in enumerate(pred_boxes):\n",
    "            if pred_class != 1: continue\n",
    "            if j in matched and calculate_iou([x1, y1, x2, y2], [px1, py1, px2, py2]) >= iou_threshold:\n",
    "                is_fn = False\n",
    "                break\n",
    "\n",
    "        if is_fn: fn_count += 1\n",
    "        color = (0, 255, 255) if not is_fn else (0, 0, 255)\n",
    "        label = f\"FN: {gt_class}\" if is_fn else f\"GT: {gt_class}\"\n",
    "        cv2.rectangle(gt_img, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "        cv2.putText(gt_img, label, (int(x1), int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    pred_img = image_rgb.copy()\n",
    "    tp_count, fp_count = 0, 0\n",
    "    for j, (pred_class, x1, y1, x2, y2) in enumerate(pred_boxes):\n",
    "        if pred_class != 1: continue  # üí• show pred only for class 1\n",
    "\n",
    "        if pred_matched_flags[j]:\n",
    "            color = (0, 255, 255)\n",
    "            label = f\"TP: {pred_class}\"\n",
    "            tp_count += 1\n",
    "        else:\n",
    "            color = (255, 0, 0)\n",
    "            label = f\"FP: {pred_class}\"\n",
    "            fp_count += 1\n",
    "        cv2.rectangle(pred_img, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "        cv2.putText(pred_img, label, (int(x1), int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    axs[0].imshow(gt_img)\n",
    "    axs[0].set_title(f\"[GT: Abnormal Only] Fold {fold} - {filename}\")\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(pred_img)\n",
    "    axs[1].set_title(f\"[Prediction] TP={tp_count}, FP={fp_count}, FN={fn_count}\")\n",
    "    axs[1].axis('off')\n",
    "    fig.text(0.5, 0.01, \"Abnormal Only ‚Äî TP: match, FP: extra, FN: missed\", ha='center', fontsize=10, style='italic')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(fold_dir, f\"{filename.rsplit('.', 1)[0]}_TP{tp_count}_FP{fp_count}_FN{fn_count}.jpg\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    fold_stats[fold][\"TP\"] += tp_count\n",
    "    fold_stats[fold][\"FP\"] += fp_count\n",
    "    fold_stats[fold][\"FN\"] += fn_count\n",
    "    if fp_count > 0 or fn_count > 0:\n",
    "        fold_stats[fold][\"Images\"] += 1\n",
    "\n",
    "# ‚úÖ Export per-fold stats\n",
    "summary_rows = [\n",
    "    {\n",
    "        \"Fold\": f\"Fold {k}\",\n",
    "        \"Images\": v[\"Images\"],\n",
    "        \"TP\": v[\"TP\"],\n",
    "        \"FP\": v[\"FP\"],\n",
    "        \"FN\": v[\"FN\"]\n",
    "    }\n",
    "    for k, v in sorted(fold_stats.items())\n",
    "]\n",
    "pd.DataFrame(summary_rows).to_csv(\"summary_per_fold.csv\", index=False)\n",
    "print(\"üìÑ Exported per-fold summary to 'summary_per_fold.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
