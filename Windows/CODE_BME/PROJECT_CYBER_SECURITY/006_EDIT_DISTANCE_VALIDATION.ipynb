{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"\n",
    "    Load a JSON file and return its content.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict or list: Parsed JSON data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "            return json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to decode JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    return None\n",
    "\n",
    "def save_progress(file_path, data):\n",
    "    \"\"\"\n",
    "    Save progress or parameters into a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the JSON file.\n",
    "        data (dict): The data to save.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        with open(file_path, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(data, json_file, indent=4, ensure_ascii=False)\n",
    "        print(f\"Progress saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save progress: {e}\")\n",
    "\n",
    "def load_progress(file_path):\n",
    "    \"\"\"\n",
    "    Load progress or parameters from a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The loaded data, or an empty dictionary if not found or failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "                return json.load(json_file)\n",
    "        else:\n",
    "            print(f\"No previous progress found at {file_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load progress: {e}\")\n",
    "    return {}\n",
    "\n",
    "def calculate_levenshtein_distances(test_values, train_values, progress_path, current_status):\n",
    "    \"\"\"\n",
    "    Calculate the Levenshtein distances between two lists of strings.\n",
    "\n",
    "    Parameters:\n",
    "        test_values (iterable): Iterable containing test strings.\n",
    "        train_values (iterable): Iterable containing train strings.\n",
    "        progress_path (str): Path to save progress JSON file.\n",
    "        current_status (dict): Current processing status.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the distances.\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    for idx, test_value in enumerate(tqdm(test_values, desc=\"Calculating Distances\")):\n",
    "        row_distances = [distance(test_value, train_value) for train_value in train_values]\n",
    "        distances.append(row_distances)\n",
    "\n",
    "        # Update progress for each test_value\n",
    "        current_status[\"last_processed_test_value\"] = idx\n",
    "        save_progress(progress_path, current_status)\n",
    "\n",
    "    return pd.DataFrame(distances, columns=train_values)\n",
    "\n",
    "# Define paths and folder structure\n",
    "main_path = r'C:\\Users\\BMEI CMU\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_CYBER_SECURITY\\RESULT\\05.DATA_VALIDATION'\n",
    "output_main_path = r'C:\\Users\\BMEI CMU\\Documents\\GitHub\\WORK\\Windows\\CODE_BME\\PROJECT_CYBER_SECURITY\\RESULT\\06.EDIT_DISTANCE_VALIDATION'\n",
    "progress_path = os.path.join(output_main_path, \"progress.json\")\n",
    "folds = [f\"fold_{i}\" for i in range(1, 5)]\n",
    "malware_variants = [f\"MALWARE_{i}\" for i in range(100, 400, 100)]\n",
    "benign_variants = [f\"BENIGN_{i}\" for i in range(100, 400, 100)]\n",
    "\n",
    "# Load previous progress\n",
    "progress = load_progress(progress_path)\n",
    "\n",
    "# Loop through each folder and process files\n",
    "for fold in folds:\n",
    "    for malware in malware_variants:\n",
    "        for benign in benign_variants:\n",
    "            folder_path = os.path.join(main_path, fold, f\"{malware}_{benign}\")\n",
    "\n",
    "            if not os.path.exists(folder_path):\n",
    "                continue\n",
    "\n",
    "            validation_test_path = os.path.join(folder_path, \"validation_test.json\")\n",
    "            validation_train_path = os.path.join(folder_path, \"validation_train.json\")\n",
    "\n",
    "            # Process validation_test.json\n",
    "            if os.path.isfile(validation_test_path):\n",
    "                validation_test_data = load_json(validation_test_path)\n",
    "                if validation_test_data:\n",
    "                    try:\n",
    "                        validation_test_df = pd.DataFrame(validation_test_data)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to convert validation_test data to DataFrame: {e}\")\n",
    "            \n",
    "            # Process validation_train.json\n",
    "            if os.path.isfile(validation_train_path):\n",
    "                validation_train_data = load_json(validation_train_path)\n",
    "                if validation_train_data:\n",
    "                    try:\n",
    "                        validation_train_df = pd.DataFrame(validation_train_data)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to convert validation_train data to DataFrame: {e}\")\n",
    "\n",
    "            # Calculate edit distances if both DataFrames are available\n",
    "            if 'validation_test_df' in locals() and 'validation_train_df' in locals():\n",
    "                if not validation_test_df.empty and not validation_train_df.empty:\n",
    "                    try:\n",
    "                        test_column = validation_test_df.columns[0]\n",
    "                        train_column = validation_train_df.columns[0]\n",
    "\n",
    "                        current_status = {\n",
    "                            \"current_fold\": fold,\n",
    "                            \"current_malware_variant\": malware,\n",
    "                            \"current_benign_variant\": benign,\n",
    "                            \"last_processed_test_value\": -1\n",
    "                        }\n",
    "\n",
    "                        distances_df = calculate_levenshtein_distances(\n",
    "                            validation_test_df[test_column], \n",
    "                            validation_train_df[train_column], \n",
    "                            progress_path, \n",
    "                            current_status\n",
    "                        )\n",
    "\n",
    "                        # Save distances to CSV with descriptive filename\n",
    "                        output_filename = f\"levenshtein_distances_{fold}_{malware}_{benign}.csv\"\n",
    "                        output_path = os.path.join(output_main_path, fold, f\"{malware}_{benign}\", output_filename)\n",
    "                        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "                        distances_df.to_csv(output_path, index=False)\n",
    "                        print(f\"Distances saved to {output_path}\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to calculate edit distances: {e}\")\n",
    "\n",
    "            break\n",
    "        break\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
