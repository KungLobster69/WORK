{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "Lottery Results Fetching Script\n",
    "\n",
    "This script fetches lottery results from an API, checks for new data, and saves results into a DataFrame.\n",
    "\n",
    "Data Source: https://lotto.api.rayriffy.com\n",
    "Author: Your Name\n",
    "Date Created: YYYY-MM-DD\n",
    "Last Updated: YYYY-MM-DD\n",
    "\"\"\"\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://lotto.api.rayriffy.com/list/\"\n",
    "\n",
    "# Column names in English\n",
    "columns_english = [\"Date\", \"1st Prize\", \"2nd Prize\", \"3rd Prize\", \"4th Prize\", \"5th Prize\", \"Front 3 Digits\", \"Back 3 Digits\", \"Back 2 Digits\"]\n",
    "\n",
    "# File path\n",
    "file_path = \"lottery_results.csv\"\n",
    "\n",
    "# Load existing data if available\n",
    "if os.path.exists(file_path):\n",
    "    existing_df = pd.read_csv(file_path, encoding=\"utf-8-sig\")\n",
    "    existing_dates = set(existing_df[\"Date\"])\n",
    "else:\n",
    "    existing_df = pd.DataFrame(columns=columns_english)\n",
    "    existing_dates = set()\n",
    "\n",
    "print(f\"Found {len(existing_dates)} existing records. Checking for updates...\")\n",
    "\n",
    "# Fetch all IDs from API\n",
    "all_ids = []\n",
    "page = 1\n",
    "while True:\n",
    "    response = requests.get(f\"{base_url}{page}\")\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data[\"status\"] == \"success\" and len(data[\"response\"]) > 0:\n",
    "            all_ids.extend([item[\"id\"] for item in data[\"response\"]])\n",
    "            page += 1\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Error fetching page {page}: Status code {response.status_code}\")\n",
    "        break\n",
    "\n",
    "print(f\"Total IDs collected: {len(all_ids)}\")\n",
    "\n",
    "# Collect lottery data not already in DataFrame\n",
    "new_data = []\n",
    "\n",
    "for lotto_id in all_ids:\n",
    "    url = f\"https://lotto.api.rayriffy.com/lotto/{lotto_id}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data[\"status\"] == \"success\":\n",
    "            date = data[\"response\"].get(\"date\", \"N/A\")\n",
    "\n",
    "            if date in existing_dates:\n",
    "                print(f\"Skipping {date}, already exists.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Adding new data for {date}\")\n",
    "\n",
    "            prizes = data[\"response\"].get(\"prizes\", [])\n",
    "            prize_first = \", \".join(prizes[0][\"number\"]) if len(prizes) > 0 else \"N/A\"\n",
    "            prize_second = \", \".join(prizes[1][\"number\"]) if len(prizes) > 1 else \"N/A\"\n",
    "            prize_third = \", \".join(prizes[2][\"number\"]) if len(prizes) > 2 else \"N/A\"\n",
    "            prize_fourth = \", \".join(prizes[3][\"number\"]) if len(prizes) > 3 else \"N/A\"\n",
    "            prize_fifth = \", \".join(prizes[4][\"number\"]) if len(prizes) > 4 else \"N/A\"\n",
    "\n",
    "            running_numbers = data[\"response\"].get(\"runningNumbers\", [])\n",
    "            front_three = \", \".join(running_numbers[0][\"number\"]) if len(running_numbers) > 0 else \"N/A\"\n",
    "            back_three = \", \".join(running_numbers[1][\"number\"]) if len(running_numbers) > 1 else \"N/A\"\n",
    "            back_two = \", \".join(running_numbers[2][\"number\"]) if len(running_numbers) > 2 else \"N/A\"\n",
    "\n",
    "            new_data.append([date, prize_first, prize_second, prize_third, prize_fourth, prize_fifth, front_three, back_three, back_two])\n",
    "\n",
    "    else:\n",
    "        print(f\"Error fetching Lotto ID {lotto_id}: Status code {response.status_code}\")\n",
    "\n",
    "if new_data:\n",
    "    new_df = pd.DataFrame(new_data, columns=columns_english)\n",
    "    final_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "    final_df.to_csv(file_path, encoding=\"utf-8-sig\", index=False)\n",
    "    print(f\"Added {len(new_data)} new records to {file_path}\")\n",
    "else:\n",
    "    print(\"No new data to update.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: ARIMA\n",
      "Accuracy: 76.57%\n",
      "Predictions saved to best_model_predictions_ARIMA.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# โหลดข้อมูล\n",
    "data = pd.read_csv('lottery_results.csv')\n",
    "\n",
    "# เตรียมข้อมูล\n",
    "data_clean = data[['Date', 'Back 2 Digits']].dropna()\n",
    "\n",
    "def convert_thai_date(date_str):\n",
    "    months = {\n",
    "        'มกราคม': '01', 'กุมภาพันธ์': '02', 'มีนาคม': '03', 'เมษายน': '04',\n",
    "        'พฤษภาคม': '05', 'มิถุนายน': '06', 'กรกฎาคม': '07', 'สิงหาคม': '08',\n",
    "        'กันยายน': '09', 'ตุลาคม': '10', 'พฤศจิกายน': '11', 'ธันวาคม': '12'\n",
    "    }\n",
    "    parts = date_str.split()\n",
    "    day = parts[0]\n",
    "    month = months[parts[1]]\n",
    "    year = str(int(parts[2]) - 543)\n",
    "    return f'{year}-{month}-{int(day):02d}'\n",
    "\n",
    "data_clean['Date'] = pd.to_datetime(data_clean['Date'].apply(convert_thai_date))\n",
    "data_clean.sort_values('Date', inplace=True)\n",
    "\n",
    "series = data_clean['Back 2 Digits'].values.reshape(-1, 1)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_series = scaler.fit_transform(series)\n",
    "\n",
    "# สร้าง supervised dataset\n",
    "def create_dataset(dataset, look_back=10):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        X.append(dataset[i:(i + look_back), 0])\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "look_back = 10\n",
    "X, y = create_dataset(scaled_series, look_back)\n",
    "\n",
    "# แบ่งชุดข้อมูล\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# ตรวจหาโมเดลที่ดีที่สุด\n",
    "mae_scores = {\n",
    "    'LSTM': mae_lstm,\n",
    "    'RF': mae_rf,\n",
    "    'ARIMA': mae_arima,\n",
    "    'Ensemble': mae_ensemble\n",
    "}\n",
    "best_model = min(mae_scores, key=mae_scores.get)\n",
    "accuracy = 100 - (mae_scores[best_model] / 99) * 100\n",
    "\n",
    "# บันทึกเฉพาะผลลัพธ์ที่ทำนายได้จากโมเดลที่ดีที่สุด\n",
    "predictions = {\n",
    "    'LSTM': lstm_pred.flatten().round().astype(int).clip(0, 99),\n",
    "    'RF': rf_pred.flatten().round().astype(int).clip(0, 99),\n",
    "    'ARIMA': arima_pred.values.round().astype(int).clip(0, 99),\n",
    "    'Ensemble': ensemble_predictions.round().astype(int).clip(0, 99)\n",
    "}\n",
    "\n",
    "best_predictions = pd.DataFrame({\n",
    "    'Prediction': predictions[best_model]\n",
    "})\n",
    "\n",
    "best_predictions.to_csv(f'best_model_predictions_{best_model}.csv', index=False)\n",
    "\n",
    "print(f'Best Model: {best_model}')\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n",
    "print(f'Predictions saved to best_model_predictions_{best_model}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
